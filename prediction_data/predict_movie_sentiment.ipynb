{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import sys\n",
    "\n",
    "# Grab config file\n",
    "sys.path.insert(0, '..')\n",
    "from config import (consumer_key, consumer_secret,\n",
    "                    access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser(), \n",
    "                 wait_on_rate_limit=False, wait_on_rate_limit_notify=False)\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Movie list to predict success\n",
    "movie_list = [\"#Gringo\", \"#TheHurricaneHeist\", \"#PreyAtNight\", \"#WrinkleInTime\", \"#LoveSimon\", \"#TombRaider\", \n",
    "              \"#PacificRimUprising\", \"#SherlockGnomes\", \"#Acrimony\", \"#ReadyPlayerOne\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What date do you want to query the movies? Must be in this format (%Y-%m-%d): 2018-03-17\n"
     ]
    }
   ],
   "source": [
    "# User input to specify search until date\n",
    "search_date = input(\"What date do you want to query the movies? Must be in this format (%Y-%m-%d): \")\n",
    "\n",
    "# \"Real Person\" Filters\n",
    "min_tweets = 5\n",
    "max_tweets = 10000\n",
    "max_followers = 2500\n",
    "max_following = 2500\n",
    "lang = \"en\"\n",
    "\n",
    "# Create list of dictionaries\n",
    "sentiment = []\n",
    "\n",
    "# Analyze each movie in list\n",
    "for movie in movie_list:\n",
    "    \n",
    "    # Assign title as search term\n",
    "    search_term = movie\n",
    "    \n",
    "    # Create variable for holding the oldest tweet\n",
    "    oldest_tweet = None\n",
    "\n",
    "    # List to hold average compound values for each movie\n",
    "    compound_list = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Loop through 18 times (total of 1800 tweets)\n",
    "        for x in range(18):\n",
    "    \n",
    "            # Get all tweets from home feed (for each page specified)\n",
    "            public_tweets = api.search(search_term, \n",
    "                                        count=100,\n",
    "                                        lang='en', \n",
    "                                        until=search_date, \n",
    "                                        max_id=oldest_tweet)\n",
    "\n",
    "            # Loop through all tweets\n",
    "            for tweet in public_tweets['statuses']:\n",
    "        \n",
    "                # Use filters to check if user meets conditions\n",
    "                if (tweet[\"user\"][\"followers_count\"] < max_followers and\n",
    "                    tweet[\"user\"][\"statuses_count\"] > min_tweets and\n",
    "                    tweet[\"user\"][\"statuses_count\"] < max_tweets and\n",
    "                    tweet[\"user\"][\"friends_count\"] < max_following and\n",
    "                    tweet[\"user\"][\"lang\"] == lang):\n",
    "        \n",
    "                    # Grab tweet data\n",
    "                    tweet_text = tweet['text']\n",
    "            \n",
    "                    # Run Vader Analysis on each tweet\n",
    "                    results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "                    compound = results[\"compound\"]\n",
    "                \n",
    "                    # Append compound value to list\n",
    "                    compound_list.append(compound)\n",
    "            \n",
    "                    # Reassign the the oldest tweet (i.e. the max_id)\n",
    "                    oldest_tweet = int(tweet[\"id_str\"])\n",
    "        \n",
    "                    # Subtract 1 so the previous oldest isn't included\n",
    "                    # in the new search\n",
    "                    oldest_tweet -= 1\n",
    "                   \n",
    "        # Store average \n",
    "        tweet_dict = {\"Movie Title\": search_term,\n",
    "                      \"Search Date\": search_date,\n",
    "                      \"Compound\": np.mean(compound_list), \n",
    "                      \"Tweet Count\": len(compound_list)}\n",
    "    \n",
    "        # Append tweet data to sentiment list\n",
    "        sentiment.append(tweet_dict)\n",
    "    \n",
    "    except RateLimitError:\n",
    "        print(\"You have exceeded Twitter's rate limit. Come back in 15 minutes and try again.\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Search Date</th>\n",
       "      <th>Tweet Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Gringo</td>\n",
       "      <td>0.213460</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#TheHurricaneHeist</td>\n",
       "      <td>0.249374</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#PreyAtNight</td>\n",
       "      <td>0.333350</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#WrinkleInTime</td>\n",
       "      <td>0.219977</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#LoveSimon</td>\n",
       "      <td>0.447294</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#TombRaider</td>\n",
       "      <td>0.261814</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#PacificRimUprising</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SherlockGnomes</td>\n",
       "      <td>0.293238</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Acrimony</td>\n",
       "      <td>-0.004519</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#ReadyPlayerOne</td>\n",
       "      <td>0.339646</td>\n",
       "      <td>2018-03-17</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Movie Title  Compound Search Date  Tweet Count\n",
       "0              #Gringo  0.213460  2018-03-17          648\n",
       "1   #TheHurricaneHeist  0.249374  2018-03-17          223\n",
       "2         #PreyAtNight  0.333350  2018-03-17          613\n",
       "3       #WrinkleInTime  0.219977  2018-03-17          554\n",
       "4           #LoveSimon  0.447294  2018-03-17          725\n",
       "5          #TombRaider  0.261814  2018-03-17          629\n",
       "6  #PacificRimUprising  0.014855  2018-03-17          610\n",
       "7      #SherlockGnomes  0.293238  2018-03-17          450\n",
       "8            #Acrimony -0.004519  2018-03-17          597\n",
       "9      #ReadyPlayerOne  0.339646  2018-03-17          856"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "movie_sent_df = pd.DataFrame(sentiment)\n",
    "\n",
    "# Reorder columns\n",
    "movie_sent_df = movie_sent_df.iloc[:,[1,0,2,3]]\n",
    "\n",
    "# Save to csv\n",
    "# movie_sent_df.to_csv(f'daily_movie_sentiment/{search_date}_movie_sentiment.csv', encoding='utf-8', index=False)\n",
    "movie_sent_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
