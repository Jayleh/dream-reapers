{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from config import (consumer_key, consumer_secret,\n",
    "                    access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser(), \n",
    "                 wait_on_rate_limit=False, wait_on_rate_limit_notify=False)\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_list = [\"#Gringo\", \"#TheHurricaneHeist\", \"#PreyAtNight\", \"#WrinkleInTime\", \"#LoveSimon\", \"#TombRaider\", \n",
    "              \"#PacificRimUprising\", \"#SherlockGnomes\", \"#Acrimony\", \"#ReadyPlayerOne\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What date do you want to query the movies? Has to be in this format (%Y-%m-%d): 2018-03-07\n"
     ]
    }
   ],
   "source": [
    "# Create list of dictionaries\n",
    "sentiment = []\n",
    "\n",
    "# Date\n",
    "search_date = input(\"What date do you want to query the movies? Has to be in this format (%Y-%m-%d): \")\n",
    "\n",
    "# \"Real Person\" Filters\n",
    "min_tweets = 5\n",
    "max_tweets = 10000\n",
    "max_followers = 2500\n",
    "max_following = 2500\n",
    "lang = \"en\"\n",
    "\n",
    "# Analyze each movie in list\n",
    "for movie in movie_list:\n",
    "    \n",
    "    # Assign title as search term\n",
    "    search_term = movie\n",
    "    \n",
    "    # Create variable for holding the oldest tweet\n",
    "    oldest_tweet = None\n",
    "\n",
    "    # List to hold average compound values for each movie\n",
    "    compound_list = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Loop through 18 times (total of 1800 tweets)\n",
    "        for x in range(18):\n",
    "    \n",
    "            # Get all tweets from home feed (for each page specified)\n",
    "            public_tweets = api.search(search_term, \n",
    "                                        count=100,\n",
    "                                        lang='en', \n",
    "                                        until=search_date, \n",
    "                                        max_id=oldest_tweet)\n",
    "\n",
    "            # Loop through all tweets\n",
    "            for tweet in public_tweets['statuses']:\n",
    "        \n",
    "                # Use filters to check if user meets conditions\n",
    "                if (tweet[\"user\"][\"followers_count\"] < max_followers and\n",
    "                    tweet[\"user\"][\"statuses_count\"] > min_tweets and\n",
    "                    tweet[\"user\"][\"statuses_count\"] < max_tweets and\n",
    "                    tweet[\"user\"][\"friends_count\"] < max_following and\n",
    "                    tweet[\"user\"][\"lang\"] == lang):\n",
    "        \n",
    "                    # Grab tweet data\n",
    "                    tweet_text = tweet['text']\n",
    "            \n",
    "                    # Run Vader Analysis on each tweet\n",
    "                    results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "                    compound = results[\"compound\"]\n",
    "                \n",
    "                    # Append compound value to list\n",
    "                    compound_list.append(compound)\n",
    "            \n",
    "                    # Reassign the the oldest tweet (i.e. the max_id)\n",
    "                    oldest_tweet = int(tweet[\"id_str\"])\n",
    "        \n",
    "                    # Subtract 1 so the previous oldest isn't included\n",
    "                    # in the new search\n",
    "                    oldest_tweet -= 1\n",
    "                   \n",
    "        # Store average \n",
    "        tweet_dict = {\"Movie Title\": search_term,\n",
    "                      \"Search Date\": search_date,\n",
    "                      \"Compound\": np.mean(compound_list), \n",
    "                      \"Tweet Count\": len(compound_list)}\n",
    "    \n",
    "        # Append tweet data to sentiment list\n",
    "        sentiment.append(tweet_dict)\n",
    "    \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Title</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Search Date</th>\n",
       "      <th>Tweet Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Gringo</td>\n",
       "      <td>0.181243</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#TheHurricaneHeist</td>\n",
       "      <td>0.573777</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#PreyAtNight</td>\n",
       "      <td>0.099852</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#WrinkleInTime</td>\n",
       "      <td>0.237686</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#LoveSimon</td>\n",
       "      <td>0.294960</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#TombRaider</td>\n",
       "      <td>0.201293</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#PacificRimUprising</td>\n",
       "      <td>0.179337</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SherlockGnomes</td>\n",
       "      <td>0.362657</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Acrimony</td>\n",
       "      <td>0.104700</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#ReadyPlayerOne</td>\n",
       "      <td>0.250243</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Movie Title  Compound Search Date  Tweet Count\n",
       "0              #Gringo  0.181243  2018-03-07           37\n",
       "1   #TheHurricaneHeist  0.573777  2018-03-07           64\n",
       "2         #PreyAtNight  0.099852  2018-03-07          213\n",
       "3       #WrinkleInTime  0.237686  2018-03-07          450\n",
       "4           #LoveSimon  0.294960  2018-03-07          510\n",
       "5          #TombRaider  0.201293  2018-03-07          543\n",
       "6  #PacificRimUprising  0.179337  2018-03-07          596\n",
       "7      #SherlockGnomes  0.362657  2018-03-07           35\n",
       "8            #Acrimony  0.104700  2018-03-07           44\n",
       "9      #ReadyPlayerOne  0.250243  2018-03-07          608"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "movie_sent_df = pd.DataFrame(sentiment)\n",
    "\n",
    "# Reorder columns\n",
    "movie_sent_df = movie_sent_df.iloc[:,[1,0,2,3]]\n",
    "\n",
    "# Save to csv\n",
    "# movie_sent_df.to_csv(f'prediction_data/{search_date}_movie_sentiment.csv', encoding='utf-8', index=False)\n",
    "movie_sent_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
