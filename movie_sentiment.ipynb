{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from config import (consumer_key, consumer_secret,\n",
    "                    access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "# Initialize Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target user\n",
    "search_term = \"Black Panther\"\n",
    "\n",
    "# Create variable for holding the oldest tweet\n",
    "oldest_tweet = None\n",
    "\n",
    "# Create list of dictionaries\n",
    "sentiment = []\n",
    "\n",
    "# Paginate through 5 pages\n",
    "for x in range(5):\n",
    "       \n",
    "    # Get all tweets from home feed (for each page specified)\n",
    "    public_tweets = api.search(search_term, \n",
    "                               count=100,\n",
    "                               lang=en,\n",
    "                               result_type=\"recent\",\n",
    "                               until=\"2018-02-16\"\n",
    "                               max_id=oldest_tweet)\n",
    "        \n",
    "    # Loop through all tweets\n",
    "    for tweet in public_tweets:\n",
    "            \n",
    "    # Grab tweet data\n",
    "    name = tweet['user']['name']\n",
    "    tweet_text = tweet['text']\n",
    "    date = tweet['created_at']\n",
    "            \n",
    "    # Run Vader Analysis on each tweet\n",
    "    results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "    compound = results[\"compound\"]\n",
    "    positive = results['pos']\n",
    "    neutral = results['neu']\n",
    "    negative = results['neg']\n",
    "            \n",
    "    # Track tweet count\n",
    "    tweets_ago = tweet_count\n",
    "            \n",
    "    # Create dictionary holding tweet data\n",
    "    tweet_dict = {'Media Source': name, 'Tweet': tweet_text, 'Date': date, 'Compound': compound, \n",
    "                  'Positive': positive, 'Neutral': neutral, 'Negative': negative, 'Tweets Ago': tweet_count}\n",
    "    \n",
    "    # Reassign the the oldest tweet (i.e. the max_id)\n",
    "        oldest_tweet = int(tweet[\"id_str\"])\n",
    "        \n",
    "    # Subtract 1 so the previous oldest isn't included\n",
    "    # in the new search\n",
    "    oldest_tweet = oldest_tweet - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
